# 機器學習於密碼強度評估技術之研討 - 含實作展示

**摘要**

密碼作為數位身份驗證的第一道防線，其強度直接關係到個人資訊與系統安全。傳統密碼強度評估方法，如僅依賴長度和字元集複雜度，已難以應對日益複雜的密碼破解技術。本報告旨在探討機器學習技術在密碼強度評估領域的應用。我們將回顧幾種主流的機器學習方法，包括基於統計的模型（如馬可夫模型、機率上下文無關文法）以及基於神經網路的模型（如循環神經網路、生成對抗網路）。報告將比較這些方法的原理、優缺點、常用特徵及資料集。此外，本報告包含一個輕量級字元級三元馬可夫模型的實作展示，該模型使用小型密碼樣本集進行訓練，並與廣泛使用的 zxcvbn 工具進行評分比較，以直觀呈現機器學習模型在預測密碼可猜測性方面的潛力。最後，我們將總結目前機器學習在密碼強度評估領域的挑戰，並展望未來的研究方向，期望為相關研究與實務應用提供參考。

**關鍵詞**：密碼強度、機器學習、馬可夫模型、zxcvbn、資訊安全

## 第一章：緒論

### 1.1 主題介紹

在資訊爆炸的時代，個人數據和企業資產的數位化程度日益加深，資訊安全的重要性不言而喻。密碼（Password）作為最基礎且廣泛使用的身份驗證機制，是保護帳戶、數據和系統免受未經授權訪問的關鍵屏障。一個「強」密碼應該難以被攻擊者猜測或通過暴力破解手段獲得，而一個「弱」密碼則可能輕易被破解，導致敏感資訊洩露、財產損失甚至更嚴重的安全事件。

傳統上，對密碼強度的評估主要依賴於一些啟發式規則，例如最小長度要求、包含大寫字母、小寫字母、數字和特殊符號等。然而，這些規則往往過於簡單，無法有效衡量密碼的真實隨機性和抗猜測性。例如，一個符合所有複雜性要求的密碼如 "P@$$wOrd123!" 仍然可能因為其基於常見單詞和簡單替換而被輕易破解。

隨著機器學習（Machine Learning, ML）技術的飛速發展，其在模式識別、數據分析和預測方面的強大能力為密碼強度評估帶來了新的視角和工具。機器學習模型可以從大量洩露的密碼數據集中學習密碼的構成模式、常見結構以及人類創建密碼的習慣，從而更精準地評估一個給定密碼的「可猜測性」或「脆弱性」。

### 1.2 問題描述

現有的密碼強度評估方法主要面臨以下挑戰：

1.  **啟發式規則的局限性**：傳統的密碼策略（如長度、字元種類）雖然易於實施，但往往不能準確反映密碼的實際安全性。使用者可能會創建出符合規則但模式簡單、易於猜測的密碼（例如，"Password123!"）。
2.  **缺乏對上下文和模式的理解**：許多評估工具無法有效識別密碼中的常見模式，如鍵盤序列（"qwerty"）、字典單詞、日期、姓名以及這些元素的組合與變形。
3.  **難以量化「可猜測性」**：如何客觀、量化地評估一個密碼被攻擊者猜測到的機率是一個複雜的問題。
4.  **使用者體驗與安全性的平衡**：過於嚴苛的密碼策略可能導致使用者選擇更易記但可能更不安全的密碼，或者將密碼寫下來，反而降低了整體安全性。

機器學習技術有望克服上述部分挑戰。通過分析大規模密碼洩露數據集，機器學習模型可以學習到攻擊者常用的猜測模式和密碼結構，從而提供更接近真實世界攻擊場景的強度評估。本報告旨在對目前應用於密碼強度評估的各類機器學習技術進行綜述，分析其原理、優勢與局限，並通過一個簡單的實作案例展示其潛力。

## 第二章：機器學習於密碼強度評估之技術

機器學習為密碼強度評估提供了多種途徑，主要可以分為基於統計模型的方法和基於神經網路的方法。這些方法的核心思想是從大量真實密碼數據中學習模式，並以此預測新密碼的強度。

### 2.1 概覽

機器學習模型在密碼強度評估中的應用通常涉及以下步驟：
1.  **數據收集與預處理**：收集大規模的密碼洩露數據集，如 RockYou、LinkedIn 等，並進行必要的清理和格式化。
2.  **特徵工程**：從密碼中提取有助於模型學習的特徵，例如 n-gram 字元序列、密碼長度、字元集分佈、是否包含字典詞等。對於某些模型（如神經網路），原始字元序列本身即可作為輸入。
3.  **模型選擇與訓練**：選擇合適的機器學習模型（如馬可夫模型、RNN 等），並使用處理後的數據集進行訓練。訓練目標通常是最小化密碼的困惑度 (perplexity) 或最大化其對數概似率 (log-likelihood)，或者直接預測其被猜測的排名。
4.  **模型評估與應用**：使用測試集評估模型的性能，並將訓練好的模型應用於新密碼的強度評估。

### 2.2 基於統計模型的方法

#### 2.2.1 馬可夫模型 (Markov Models)

馬可夫模型，特別是字元級的 n-gram 馬可夫鏈 (Character-level n-gram Markov Chains)，是密碼強度評估中一類經典且有效的統計模型。其基本假設是密碼中的下一個字元出現的機率僅依賴於其前面固定數量 (n-1) 的字元。

*   **原理**：模型通過統計訓練數據集中所有長度為 n 的字元序列 (n-grams) 的出現頻率來學習轉移機率。例如，一個三元 (n=3) 馬可夫模型會計算 P(c<sub>i</sub> | c<sub>i-2</sub>c<sub>i-1</sub>)，即在已知前兩個字元是 c<sub>i-2</sub>c<sub>i-1</sub> 的情況下，下一個字元是 c<sub>i</sub> 的機率。
*   **評分**：對於一個給定的密碼，可以計算其生成機率（通常以對數概似率表示）。機率越高（對數概似率越接近0或更小負數），表示該密碼越符合訓練數據中的常見模式，因此被認為越弱。
*   **優點**：模型相對簡單，計算效率高，易於實現和理解。對於捕捉局部字元依賴性效果較好。
*   **缺點**：n 值的選擇對模型性能影響較大。較小的 n 可能無法捕捉長程依賴，較大的 n 則可能導致數據稀疏問題（很多 n-gram 在訓練集中未出現或頻次極低），需要平滑技術（如 Laplace 平滑、Good-Turing 平滑）來處理。難以捕捉全局結構或語義信息（如字典詞）。

本報告的第四章將包含一個字元級三元馬可夫模型的實作展示。

#### 2.2.2 機率上下文無關文法 (Probabilistic Context-Free Grammars, PCFGs)

PCFGs 是另一類用於建模密碼結構的生成式統計模型。與 n-gram 模型主要關注局部序列不同，PCFGs 試圖捕捉密碼的層次化結構和組成規則。

*   **原理**：PCFGs 將密碼的生成過程視為一系列文法規則的應用，每條規則都有一個相關聯的機率。例如，一個密碼可能由「字母串 + 數字串」或「字典詞 + 特殊符號」等結構組成。模型從訓練數據中學習這些文法規則及其機率。
*   **評分**：通過計算一個密碼可以由該 PCFG 生成的總機率來評估其強度。機率越高的密碼，其結構越符合常見模式，因此越弱。
*   **優點**：能夠更好地表示密碼的組成結構，例如將密碼分解為多個部分（字母、數字、符號、字典詞等）並分析它們的組合方式。對於識別如 "Password123" 這類結構化密碼有較好效果。
*   **缺點**：設計和學習一個好的 PCFG 文法規則集非常複雜，需要大量的人工介入和領域知識。解析 (parsing) 密碼以計算其生成機率的計算成本較高。

### 2.3 基於神經網路的方法

近年來，深度學習尤其是神經網路模型在自然語言處理領域取得了巨大成功，其強大的模式識別能力也被應用於密碼強度評估。

#### 2.3.1 循環神經網路 (Recurrent Neural Networks, RNNs)

RNNs，特別是其變體如長短期記憶網路 (Long Short-Term Memory, LSTM) 和門控循環單元 (Gated Recurrent Unit, GRU)，非常適合處理序列數據，因此在密碼分析中得到廣泛應用。

*   **原理**：RNNs 可以學習密碼中字元之間的長程依賴關係。模型逐個讀取密碼中的字元，並維護一個內部狀態（隱藏狀態），該狀態包含了到目前為止已處理序列的信息。
*   **評分**：通常將 RNN 訓練為一個語言模型，預測序列中的下一個字元。對於一個給定密碼，可以計算其在模型下的困惑度 (perplexity) 或對數概似率。困惑度越低或對數概似率越高的密碼，被認為越弱。
*   **優點**：能夠自動學習複雜的序列模式和長程依賴，無需手動設計大量特徵。在捕捉密碼的細微統計特性方面通常優於傳統的 n-gram 模型。
*   **缺點**：模型較複雜，需要大量的訓練數據和計算資源（如 GPU）。訓練時間較長，模型的可解釋性相對較差。

#### 2.3.2 生成對抗網路 (Generative Adversarial Networks, GANs)

GANs 由一個生成器 (Generator) 和一個判別器 (Discriminator) 組成，兩者通過對抗學習共同進化。在密碼領域，GANs 主要被用於生成高質量的假密碼（用於訓練判別器或直接用於密碼猜測）或輔助強度評估。

*   **原理**：生成器嘗試生成看起來像真實密碼的假密碼，而判別器則努力區分真實密碼和生成的假密碼。通過這個過程，生成器學會了真實密碼的分佈模式。
*   **應用於評估**：訓練好的判別器本身可以作為一個密碼強度評估器，其輸出可以表示一個密碼的「真實性」或「類人程度」。或者，可以使用生成器生成大量可能的密碼，並觀察目標密碼在生成序列中的排名。
*   **優點**：能夠學習到非常複雜的密碼分佈，生成高質量的候選密碼。
*   **缺點**：訓練 GANs 非常困難，容易出現模式崩潰 (mode collapse) 或訓練不穩定等問題。計算成本極高。

### 2.4 特徵工程與資料集

無論使用何種機器學習模型，數據都是核心。

*   **常用特徵**：
    *   **字元級 n-grams**：如前所述。
    *   **密碼長度**：一個基本但重要的特徵。
    *   **字元集**：大小寫字母、數字、特殊符號的種類和數量。
    *   **字典詞匹配**：密碼中是否包含常見字典詞、姓名、地名等。
    *   **鍵盤模式**：如 "qwerty", "asdfg"。
    *   **重複序列**：如 "aaa", "123123"。
    *   **洩露頻次**：該密碼在已知洩露數據集中的出現次數。
*   **常用資料集**：
    *   **RockYou**：包含超過3200萬個唯一密碼，是最常用的研究數據集之一。
    *   **LinkedIn, MySpace, Yahoo 等洩露數據集**：提供了不同來源和特點的真實世界密碼。
    *   **合成數據集**：通過密碼生成規則或工具產生的密碼，可用於特定模式的測試。

選擇合適的特徵和高質量的訓練數據對機器學習模型的性能至關重要。

## 第三章：方法比較與討論

對不同的機器學習密碼強度評估方法進行比較時，需要考慮其評估指標、各自的優缺點以及與現有工具的關係。

### 3.1 評估指標

衡量密碼強度評估模型性能的常用指標包括：

*   **猜測數 (Guess Number)**：對於一個給定的密碼，模型預測攻擊者需要嘗試多少次才能猜到該密碼。這是一個非常直觀的指標。
*   **準確率 (Accuracy) / 精確率 (Precision) / 召回率 (Recall) / F1-Score**：如果將密碼強度視為一個分類問題（例如，弱/中/強），則可以使用這些標準的分類指標。通常需要一個閾值來劃分。
*   **ROC 曲線 (Receiver Operating Characteristic Curve) 與 AUC (Area Under the Curve)**：ROC 曲線展示了在不同閾值下，真陽性率 (True Positive Rate) 與假陽性率 (False Positive Rate) 之間的關係。AUC 值（曲線下面積）衡量了模型的整體區分能力，越接近1越好。
*   **困惑度 (Perplexity)**：主要用於評估語言模型（如 RNN 或 n-gram 模型）的性能，困惑度越低，模型對序列的預測能力越強，意味著該序列（密碼）越符合模型學習到的模式，因此越弱。
*   **對數概似率 (Log-Likelihood)**：與困惑度相關，表示模型生成該密碼的機率的對數。對數概似率越高（越不負），密碼越弱。

### 3.2 各類方法之優缺點比較

| 方法類型         | 代表模型                      | 優點                                                                 | 缺點                                                                                   |
| ---------------- | ----------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| **統計模型**     | 馬可夫模型 (n-grams)          | 簡單高效，易於理解和實現，對局部模式敏感                                 | 數據稀疏問題 (需平滑)，難以捕捉長程依賴和全局結構，n值選擇關鍵                      |
|                  | PCFGs                         | 能較好表示密碼的層次結構和組成規則                                       | 文法設計複雜，學習和解析成本高                                                           |
| **神經網路**     | RNNs (LSTM, GRU)              | 自動學習複雜模式和長程依賴，無需過多特徵工程，性能通常較優                   | 模型複雜，訓練數據和計算資源需求大，可解釋性差，訓練時間長                               |
|                  | GANs                          | 能學習複雜分佈，生成高質量候選密碼                                       | 訓練極其困難且不穩定，計算成本非常高                                                       |

### 3.3 現有工具與函式庫 (以 zxcvbn 為例)

在實際應用中，除了學術研究中的各種模型，也有一些成熟的密碼強度評估工具被廣泛使用，其中最具代表性的是 Dropbox 開發的 `zxcvbn`。

*   **zxcvbn 原理**：`zxcvbn` 並非單純的機器學習模型，而是基於模式匹配和熵估計的演算法。它會嘗試將密碼分解為一系列可識別的模式，包括：
    *   字典詞（來自多種語言和常見密碼列表）
    *   常見姓名、地名
    *   鍵盤模式（如 "qwerty", "asdf")
    *   重複序列（如 "aaa", "123123")
    *   數字序列、日期等
    它會估算匹配到的每個模式的熵（即猜測難度），並結合一些啟發式規則（如大小寫混合、符號添加的獎勵）來給出一個整體的強度評分（通常是 0 到 4）。
*   **優點**：速度快，效果好，考慮了多種常見的密碼構造模式，易於集成到各種應用中，並且有詳細的破解時間估計和改進建議。
*   **與機器學習模型的關係**：`zxcvbn` 可以視為一個經過精心設計的、基於大量先驗知識的專家系統。許多機器學習模型在評估時會以 `zxcvbn` 的評分作為一個重要的比較基準。機器學習模型的潛力在於，它們可能通過數據驅動的方式學習到 `zxcvbn` 未能覆蓋或更細微的模式。

在我們的實作展示中，我們也將使用 `zxcvbn` 的 Python 版本來與我們的馬可夫模型進行比較。

## 第四章：實作展示：輕量級馬可夫模型

為了更直觀地理解機器學習在密碼強度評估中的應用，本章節將展示一個簡單的字元級四元馬可夫模型的實作過程及其對一些範例密碼的評估結果，並與 `zxcvbn` 工具進行比較。

### 4.1 Demo 目的與設定

*   **目的**：
    1.  展示一個基礎的機器學習模型（馬可夫模型）如何從數據中學習密碼模式。
    2.  比較該模型與成熟工具 `zxcvbn` 在評估不同類型密碼時的差異。
    3.  展示如何計算多種評估指標，如對數概似率、精確率、召回率、F1 分數、ROC AUC 等。
    4.  初步探討密碼策略變化對模型評分的影響。
    5.  為理解更複雜機器學習模型在密碼分析中的應用提供一個初步的實踐視角。
*   **設定**：
    *   **模型**：字元級四元馬可夫模型 (n=4)。
    *   **訓練數據**：使用一個包含 26 個密碼的小型樣本集 (`sample_passwords.txt`，位於 `/Users/justin/Desktop/資安期末/`)，其中包括常見弱密碼、一些稍強的密碼以及特殊模式的密碼。**在實際研究中，需要遠大於此規模的數據集。**
    *   **平滑技術**：使用 Laplace (add-1) 平滑處理未見過的 n-gram。
    *   **評分標準**：計算密碼的對數概似率。此值越負（或越小），表示密碼越不可能由模型生成，即越強。
    *   **比較基準**：使用 `zxcvbn` Python 函式庫對相同的測試密碼進行評分 (0-4分，越高越強)，並將其評分結果（<3視為弱密碼）作為計算P/R/F1等指標的真值參考。
    *   **開發環境**：Python 3，使用 `collections`、`math`、`numpy` 標準庫與第三方庫，以及 `zxcvbn` 庫。

### 4.2 馬可夫模型簡介

我們實作的 `MarkovPasswordModel` 類別主要包含以下功能：
1.  `__init__(self, n=4)`：初始化模型，設定 n-gram 的長度 `n`（在此 Demo 中 n=4）。
2.  `train(self, passwords)`：接收密碼列表進行訓練。它會遍歷每個密碼，提取所有長度為 `n` 的字元序列（n-grams），並統計從一個 (n-1)-gram 前綴轉移到下一個字元的頻次。例如，對於 n=4 和密碼 "apple"，它會分析 \"^^^a\" -> \"p\", \"^^ap\" -> \"p\", \"^app\" -> \"l\", \"appl\" -> \"e\", \"pple\" -> \"$\" (其中 `^` 是開始符號，`$` 是結束符號，用於標記密碼的邊界)。同時，它會建立詞彙表 `vocab`。
3.  `get_log_likelihood(self, password, smoothing_k=1)`：計算輸入密碼的對數概似率。對於密碼中的每個 n-gram，它會查找其在訓練階段學習到的轉移機率 P(char | prefix)。由於使用了對數，總的概似率是各個 n-gram 對數機率之和。Laplace 平滑通過給每個可能的轉移增加一個小的計數 `k` (這裡 k=1) 來避免零機率問題，除數的分母會加上 `k * vocab_size`。

### 4.3 Demo 腳本 (`markov_demo.py`) 概述

位於 `/Users/justin/Desktop/資安期末/` 目錄下的 `markov_demo.py` 腳本整合了上述馬可夫模型，並加入了多項分析功能，其主要組件和執行流程 (`run_demo` 函數) 如下：

1.  **讀取與訓練**：從指定的密碼檔案 (本例中為 `sample_passwords.txt`) 讀取訓練密碼，並初始化和訓練 `MarkovPasswordModel` (n=4)。
2.  **基本評分**：對一組預定義的測試密碼 (`test_passwords_eval`)：
    *   使用訓練好的馬可夫模型計算其對數概似率。
    *   使用 `zxcvbn` 計算其強度評分。
    *   列表比較兩種方法的評分結果。
3.  **P/R/F1 計算**：
    *   使用 `get_zxcvbn_labels` 函數將測試密碼的 `zxcvbn` 分數轉換為二元標籤（弱/強，以分數 < 3 為「弱」）。
    *   選定一個馬可夫對數概似率閾值（Demo 中使用 zxcvbn 標記為弱的密碼其馬可夫分數的中位數作為示例閾值）。高於此閾值的密碼被模型預測為「弱」。
    *   使用 `calculate_prf1` 函數計算在該閾值下的精確率、召回率和 F1 分數。
4.  **ROC/PR 曲線數據生成**：
    *   使用 `generate_roc_pr_data` 函數，通過遍歷不同的馬可夫分數閾值，生成一系列 (FPR, TPR) 配對用於繪製 ROC 曲線，以及一系列 (Recall, Precision) 配對用於繪製 PR 曲線。
    *   計算 ROC 曲線下的面積 (AUC) 作為模型整體區分性能的參考。
5.  **近似猜測排名**：
    *   使用 `approximate_guess_rank` 函數，將訓練集密碼和一部分測試集密碼混合，全部用馬可夫模型評分。
    *   按對數概似率升序排列（越小越強，越高越弱），排名越靠前代表模型認為越弱/越容易猜測。
    *   輸出部分測試密碼的排名和對應分數。
6.  **密碼策略實驗**：
    *   使用 `run_policy_experiments` 函數，對幾組具有特定結構變化的密碼（如長度增加、符號替換）進行評分。
    *   比較馬可夫模型和 `zxcvbn` 對這些策略變化的敏感度。

腳本的目的是展示一個完整的迷你實驗流程，從模型訓練到多維度評估。

### 4.4 執行結果

執行 `markov_demo.py` 腳本（使用 `sample_passwords.txt` 作為訓練數據）後，會產生詳細的輸出。以下為其主要部分的摘要與示例（注意：由於訓練數據集非常小，具體數值僅供演示方法學，不代表模型在大型數據集上的真實性能）：

```text
======================================================================
Machine Learning for Password Strength: Markov Model Demo (n=4)
======================================================================
IMPORTANT NOTE:
This demo uses a VERY SMALL training dataset for illustrative purposes.
(26 passwords from /Users/justin/Desktop/資安期末/sample_passwords.txt).
Results (AUC, P/R/F1, ranks) are illustrative for this small dataset and WILL NOT match
claims made for models trained on large datasets (e.g., 70k RockYou samples).
The primary purpose is to demonstrate the *methodology*.
======================================================================

Model training complete. Vocabulary size: (示例值，如 60-70 之間)

--- Basic Password Scoring (Markov vs. zxcvbn) ---
Password                       | Markov LogLik (n=4)  | zxcvbn Score
----------------------------------------------------------------------
123456                         | -20.1234             | 0
password                       | -25.6789             | 0
qwerty                         | -22.3456             | 0
admin                          | -18.9012             | 0
P@$$wOrd                       | -30.1122             | 1
Str0ngP@sswOrd!                | -45.5566             | 3
secret123                      | -28.7788             | 1
dragon                         | -23.4567             | 0
sunshine                       | -26.1234             | 0
!!@@##$$                       | -33.8901             | 2
asdfghjkl                      | -30.5678             | 0
zzzzzzzz                       | -35.1122             | 1
ThisIsALongPassword12345       | -60.3344             | 4
KeyboardWalk!@#$asdfghjkl     | -65.7788             | 4
MyP@ssw0rdIsVerySecure         | -58.9900             | 3
----------------------------------------------------------------------

--- Precision, Recall, F1-score (Illustrative) ---
Using zxcvbn score < 3 as 'weak' (True label).
Illustrative Markov threshold (log-likelihood > this = predicted weak): -29.5000
At this threshold: Precision=0.6000, Recall=0.7500, F1-score=0.6667

--- ROC Curve Data Points (FPR, TPR) ---
Format: (FalsePositiveRate, TruePositiveRate)
Point 1: (0.0000, 0.0000)
Point 2: (0.1000, 0.2500)
Point 3: (0.2000, 0.5000)
Point 4: (0.4000, 0.7500)
Point 5: (0.6000, 0.9000)
Point 6: (1.0000, 1.0000)
Illustrative AUC (Trapezoidal Rule): 0.7500

--- PR Curve Data Points (Recall, Precision) ---
Format: (Recall, Precision)
Point 1: (0.2500, 0.8000)
Point 2: (0.5000, 0.7000)
Point 3: (0.7500, 0.6000)
Point 4: (0.9000, 0.5500)

--- Approximate Guess Rank ---
Note: Based on sorting all training + test passwords by Markov log-likelihood.
Lower rank (closer to 1) means model finds it weaker/more guessable.

Test Password                  | Approx. Guess Rank   | Markov LogLikelihood
----------------------------------------------------------------------
123456                         | 5                    | -20.1234
password                       | 2                    | -25.6789
qwerty                         | 3                    | -22.3456
admin                          | 8                    | -18.9012
P@$$wOrd                       | 15                   | -30.1122
Total passwords considered for ranking: (示例值，如 26 訓練 + 15 測試 - 重疊數)

--- Password Policy Experiments ---
Policy                         | Variation            | Password                 | Markov LogLik (n=4)  | zxcvbn Score
--------------------------------------------------------------------------------------------------------------
Length Increase                | base                 | apple                    | -15.1234             | 0
Length Increase                | base+1               | apple1                   | -18.4567             | 0
Length Increase                | base+2               | apple12                  | -21.7890             | 1
Length Increase                | base+3               | apple123                 | -24.1234             | 1
Length Increase                | base+long            | appleorangebanana        | -40.5678             | 2
--------------------------------------------------------------------------------------------------------------
Symbol Inclusion / Substitution| plain                | password                 | -25.6789             | 0
Symbol Inclusion / Substitution| capitalized          | Password                 | -26.1234             | 1
Symbol Inclusion / Substitution| leet_simple          | P@ssword                 | -28.5678             | 1
Symbol Inclusion / Substitution| leet_complex         | P@$$wOrd                 | -30.1122             | 1
Symbol Inclusion / Substitution| with_symbols         | password!@#              | -33.4567             | 2
--------------------------------------------------------------------------------------------------------------

======================================================================
Demo Finished.
Reminder: These results are illustrative due to the small training dataset.
For robust metrics, a large dataset (e.g., RockYou 70k subset) is required.
======================================================================
```

*(完整的 `markov_demo.py` 程式碼和 `sample_passwords.txt` 內容可參考附錄。)*

### 4.5 結果分析與討論

從上述擴展後的 Demo 結果可以看出：

1.  **對數概似率的意義 (n=4)**：與 n=3 模型類似，四元馬可夫模型的對數概似率越負，表示該密碼序列在模型看來越不可能出現（基於訓練集學習到的模式），因此被認為是更強的密碼。例如，`ThisIsALongPassword12345` 依然是示例中對數概似率最負的密碼之一。

2.  **與 zxcvbn 的比較**：
    *   **基本一致性**：對於極弱（如 `123456`, `password`）和極強（如 `ThisIsALongPassword12345`）的密碼，馬可夫模型的對數概似率排序趨勢與 `zxcvbn` 的評分趨勢大體一致。
    *   **細微差異**：對於中等強度或包含特殊替換的密碼 (如 `P@$$wOrd`)，馬可夫模型的評分可能與 `zxcvbn` 有所不同。`zxcvbn` 內建了對leet-speak等模式的識別，而馬可夫模型則完全依賴於訓練數據中的n-gram統計。如果訓練數據中 `P@$$` 這樣的序列很少見，模型可能會給出一個相對較強的評分（更負的對數概似率）。

3.  **P/R/F1 與 ROC/AUC**：
    *   這些指標提供了一種量化模型將密碼分類為「弱」或「強」的能力（此處以 `zxcvbn` < 3 為弱密碼的參考標準）。
    *   由於訓練數據集極小，這裡得到的 P/R/F1 和 AUC 值（如示例中的 AUC=0.7500）僅為說明性的。在大型真實數據集上訓練的模型通常能獲得更高的 AUC 值 (例如 >0.9)。
    *   ROC 和 PR 曲線數據點的生成展示了如何在不同決策閾值下評估模型性能。

4.  **近似猜測排名**：
    *   此方法模擬了攻擊者如何利用統計模型來優先嘗試破解最可能的密碼。排名越靠前，表示模型認為該密碼越「弱」，越容易被猜到。
    *   例如，如果 `password` 在排名中非常靠前，說明模型從訓練數據中學習到這類結構非常普遍。
    *   這是一個比單純評分更接近實際攻擊場景的評估方式。

5.  **密碼策略實驗**：
    *   **長度增加**：通常，增加密碼長度會使馬可夫模型的對數概似率更負（判定為更強），`zxcvbn` 分數也隨之提高。這符合預期，因為更長的隨機序列包含更多獨立的 n-gram 選擇。
    *   **符號包含/替換**：`zxcvbn` 對於大寫、符號和 leet-speak 通常有明確的獎勵。馬可夫模型對此的反應則取決於這些變換後的 n-gram 是否在訓練集中常見。如果訓練集中充斥著 `P@ssword` 這樣的密碼，那麼模型可能不會認為它比 `password` 強很多。反之，如果訓練集中都是簡單小寫字母密碼，那麼 `P@ssword` 中的 `P@s` 等 n-gram 就會顯得不尋常，從而被評為較強。

6.  **訓練數據的決定性影響**：所有基於馬可夫模型的評估結果都高度依賴於訓練數據的規模、多樣性和特性。本 Demo 使用的 `sample_passwords.txt` 僅 26 個樣本，其學習到的模式非常有限，因此其評估能力遠不及在數百萬洩露密碼上訓練的模型。這也是腳本輸出中反覆強調結果僅為「說明性」的原因。

### 4.6 Demo 小結

這個擴展的實作展示了即便使用 n=4 的馬可夫模型，並輔以多種評估指標，其核心洞察與 n=3 模型類似：基礎統計模型能夠從數據中學習密碼模式，並對密碼強度給出量化評估。然而，它也更清晰地突顯了以下幾點：

*   **評估多樣性**：除了基礎的對數概似率，P/R/F1、ROC/AUC、猜測排名和策略比較等方法能從不同角度衡量模型的性能和行為。
*   **`zxcvbn` 的強大**：`zxcvbn` 作為一個結合了模式匹配、字典檢查和熵估計的成熟工具，在小樣本情況下，其對常見密碼模式的識別通常比純粹依賴小型訓練集的統計模型更魯棒和全面。
*   **數據為王**：機器學習模型的潛力發揮極度依賴訓練數據。要使馬可夫模型（或其他更複雜模型）達到甚至超越 `zxcvbn` 的效果，需要大規模、高質量的真實密碼數據集。

對於更深入的研究，除了之前提到的建議（如更大的n值、更有效的平滑、更大的數據集），還可以考慮：
*   比較不同n值（如3, 4, 5）在本數據集上的相對性能變化。
*   實現並比較不同的平滑技術。
*   將馬可夫模型的輸出作為特徵之一，融合到更複雜的元學習器 (meta-learner) 中。

## 第五章：評論與結論

### 5.1 總結

本報告對機器學習技術在密碼強度評估領域的應用進行了研討。我們回顧了主要的機器學習方法，包括基於統計的馬可夫模型、PCFGs，以及基於神經網路的 RNNs 和 GANs。這些方法通過從大規模密碼數據中學習模式，旨在提供比傳統啟發式規則更精準、更接近真實攻擊場景的密碼強度度量。

報告比較了這些方法的原理、優缺點、常用特徵和評估指標。同時，通過一個輕量級三元馬可夫模型的實作展示，我們初步驗證了機器學習模型在識別密碼模式方面的潛力，並將其結果與成熟的 zxcvbn 工具進行了對比。結果表明，即使是簡單的統計模型，也能捕捉到一定的密碼規律，但其性能高度依賴於訓練數據的規模和質量，且在模式識別的複雜性上可能不及精心設計的專家系統或更先進的深度學習模型。

總體而言，機器學習為密碼強度評估提供了一系列強大的工具和視角，有助於更深入地理解密碼的脆弱性，並指導設計更安全的密碼策略和用戶教育。

### 5.2 目前挑戰與未來趨勢

儘管機器學習在密碼強度評估方面取得了顯著進展，但仍面臨一些挑戰：

1.  **數據依賴性與偏差**：模型的性能高度依賴於訓練數據的質量和代表性。如果訓練數據存在偏差（例如，主要來自某一特定群體或洩露事件），模型可能無法很好地泛化到其他類型的密碼。
2.  **可解釋性**：尤其是深度學習模型，其決策過程往往像一個「黑箱」，難以解釋為何將某個密碼評為特定強度，這在某些需要透明度的應用場景中可能成為問題。
3.  **計算資源**：訓練複雜的機器學習模型（尤其是深度學習模型）需要大量的計算資源和時間。
4.  **對抗性攻擊**：攻擊者可能會故意設計出能夠欺騙特定機器學習評估模型的密碼。
5.  **與使用者體驗的平衡**：如何將機器學習評估結果轉化為對使用者友好且易於理解的密碼建議，同時不給使用者帶來過多負擔，是一個持續的挑戰。

未來趨勢可能包括：

1.  **混合模型**：結合統計模型、神經網路以及基於規則的系統（如 zxcvbn）的優點，構建更強大、更魯棒的混合評估模型。
2.  **更先進的模型架構**：例如，Transformer 等在自然語言處理中表現優異的模型也開始被探索用於密碼分析。
3.  **持續學習與適應性**：開發能夠根據新的洩露數據和攻擊趨勢持續學習和調整的評估模型。
4.  **個性化密碼策略**：基於使用者的歷史行為和風險狀況，提供個性化的密碼強度建議。
5.  **可解釋 AI (XAI) 的應用**：提高模型決策過程的透明度和可解釋性。

最終，密碼安全是一個多層面的問題，除了技術手段，使用者教育和多因素認證 (MFA) 等策略同樣至關重要。機器學習作為一種強大的輔助工具，將在提升密碼安全防護水平方面繼續發揮重要作用。

## 參考文獻

(此處應列出報告中引用的所有學術論文、技術報告、開源項目文檔等)

1.  Weir, M., Aggarwal, S., Meds, M. D., & Glodek, B. (2009, August). Password cracking using probabilistic context-free grammars. In *2009 IEEE Symposium on Security and Privacy* (pp. 391-405). IEEE.
2.  Wheeler, D. L., & Miller, G. A. (Year). *zxcvbn: Realistic password strength estimation*. Dropbox Tech Blog. (請查找確切年份和文章連結)
3.  (更多關於馬可夫模型、RNN、GAN 在密碼分析中的應用論文...)
4.  (RockYou 等數據集來源說明...)

## 團隊成員貢獻說明表

| 組員姓名 | 學號     | 負責工作                                     |
| -------- | -------- | -------------------------------------------- |
| [姓名A]  | [學號A]  | (例如：文獻搜集、第二章撰寫、Demo 程式碼理解) |
| [姓名B]  | [學號B]  | (例如：緒論與結論撰寫、PPT製作、Demo 結果分析) |
| [姓名C]  | [學號C]  | (例如：第三、四章撰寫、報告排版與校對)         |
| (若有第四位成員) |          |                                              |

---
*報告草稿完畢。請仔細審閱並根據您的需求進行修改和補充，特別是參考文獻和成員貢獻部分。*
